{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAD_1_1: Feature Extraction after Hair Removal [SIFT].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWoIbttKJQDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685dca88-ca66-47bc-d3b9-a7596dc36bf5"
      },
      "source": [
        "!pip install opencv-python==3.4.2.17 opencv-contrib-python==3.4.2.17\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "\n",
        "\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python==3.4.2.17\n",
            "  Downloading opencv_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (25.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0 MB 99 kB/s \n",
            "\u001b[?25hCollecting opencv-contrib-python==3.4.2.17\n",
            "  Downloading opencv_contrib_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (30.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==3.4.2.17) (1.19.5)\n",
            "Installing collected packages: opencv-python, opencv-contrib-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-contrib-python-3.4.2.17 opencv-python-3.4.2.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jddSkxkdd_fk",
        "outputId": "d7930dfc-2333-4816-deb7-02ab86109dab"
      },
      "source": [
        "drive.mount('/drive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDLO55B6eA7R"
      },
      "source": [
        "train_Les = np.load('/drive/My Drive/CAD_1_1/train_Les_hairRemoved.npz',allow_pickle=True)\n",
        "train_NV  = np.load('/drive/My Drive/CAD_1_1/train_NV_hairRemoved.npz',allow_pickle=True)\n",
        "val_Les   = np.load('/drive/My Drive/CAD_1_1/val_Les_hairRemoved.npz',allow_pickle=True)\n",
        "val_NV    = np.load('/drive/My Drive/CAD_1_1/val_NV_hairRemoved.npz',allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fgdqB4ufABU"
      },
      "source": [
        "trainX_Les  = np.array(train_Les['arr_0'])\n",
        "trainX_NV   = np.array(train_NV['arr_0'])\n",
        "valX_Les    = np.array(val_Les['arr_0'])\n",
        "valX_NV     = np.array(val_NV['arr_0'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa0H2zORiR7N",
        "outputId": "df82f5b7-48c9-4a39-f706-0a408d9f5a66"
      },
      "source": [
        "print(trainX_Les.shape)\n",
        "print(trainX_NV.shape)\n",
        "print(valX_Les.shape)\n",
        "print(valX_NV.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2400, 450, 600, 3)\n",
            "(2400, 450, 600, 3)\n",
            "(600, 450, 600, 3)\n",
            "(600, 450, 600, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Z4wO1wkrNF"
      },
      "source": [
        "sift=cv2.xfeatures2d.SIFT_create()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QCNyBWCnuRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241d5ffa-45ae-41f2-b2df-49f63a4489f8"
      },
      "source": [
        "siftFeatures_trainX_Les  = []\n",
        "siftFeatures_trainX_NV   = []\n",
        "siftFeatures_valX_Les    = []\n",
        "siftFeatures_valX_NV     = []\n",
        "\n",
        "for x in tqdm(trainX_Les):\n",
        "  kp, des = sift.detectAndCompute(x, None)\n",
        "  if des is not None:\n",
        "    siftFeatures_trainX_Les.append(des)\n",
        "\n",
        "for x in tqdm(trainX_NV):\n",
        "  kp, des = sift.detectAndCompute(x, None)\n",
        "  if des is not None:\n",
        "    siftFeatures_trainX_NV.append(des)\n",
        "\n",
        "for x in tqdm(valX_Les):\n",
        "  kp, des = sift.detectAndCompute(x, None)\n",
        "  if des is not None:\n",
        "    siftFeatures_valX_Les.append(des)\n",
        "\n",
        "for x in tqdm(valX_NV):\n",
        "  kp, des = sift.detectAndCompute(x, None)\n",
        "  if des is not None:\n",
        "    siftFeatures_valX_NV.append(des)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2400/2400 [02:46<00:00, 14.39it/s]\n",
            "100%|██████████| 2400/2400 [02:43<00:00, 14.72it/s]\n",
            "100%|██████████| 600/600 [00:42<00:00, 14.23it/s]\n",
            "100%|██████████| 600/600 [00:40<00:00, 14.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d97jURPg5XEA"
      },
      "source": [
        "siftFeatures_trainX_Les  = np.vstack(siftFeatures_trainX_Les)\n",
        "siftFeatures_trainX_NV   = np.vstack(siftFeatures_trainX_NV)\n",
        "siftFeatures_valX_Les    = np.vstack(siftFeatures_valX_Les)\n",
        "siftFeatures_valX_NV     = np.vstack(siftFeatures_valX_NV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QggVPv-agnSq",
        "outputId": "45a7c4c0-3b74-4820-b141-e5e6110cf81e"
      },
      "source": [
        "print(siftFeatures_trainX_Les.shape)\n",
        "print(siftFeatures_trainX_NV.shape)\n",
        "print(siftFeatures_valX_Les.shape)\n",
        "print(siftFeatures_valX_NV.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150868, 128)\n",
            "(73478, 128)\n",
            "(39553, 128)\n",
            "(19581, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py-JH5tLHg62"
      },
      "source": [
        "kmeans_siftFeatures_trainX = MiniBatchKMeans(n_clusters=2*10, batch_size=trainX_Les.shape[0]*3*2, verbose=0).fit(np.concatenate((siftFeatures_trainX_Les,siftFeatures_trainX_NV)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvTo4ywKQtZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986d8118-dd84-4cf8-f74a-a26eab839d13"
      },
      "source": [
        "\n",
        "histo_siftFeatures_trainX = []\n",
        "\n",
        "\n",
        "for x in tqdm(np.concatenate((trainX_Les,trainX_NV),axis=0)):\n",
        "  kp, des = sift.detectAndCompute(x, None)\n",
        "\n",
        "  histo = np.zeros(2*10)\n",
        "  nkp = np.size(kp)\n",
        "\n",
        "  if des is not None:\n",
        "    kmeans_siftFeatures_trainX.predict(des)\n",
        "    # hist = plt.hist()\n",
        "    for d in des:\n",
        "      idx = kmeans_siftFeatures_trainX.predict([d])\n",
        "      histo[idx] += 1/nkp # Because we need normalized histograms, I prefere to add 1/nkp directly\n",
        "\n",
        "  histo_siftFeatures_trainX.append(histo)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4800/4800 [08:09<00:00,  9.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6P7lWpkDLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e03954-d854-41f4-a9c5-fa670d35c042"
      },
      "source": [
        "histo_siftFeatures_valX = []\n",
        "\n",
        "\n",
        "for x in tqdm(np.concatenate((valX_Les,valX_NV),axis=0)):\n",
        "  kp, des = sift.detectAndCompute(x, None)\n",
        "\n",
        "  histo = np.zeros(2*10)\n",
        "  nkp = np.size(kp)\n",
        "\n",
        "  if des is not None:\n",
        "    kmeans_siftFeatures_trainX.predict(des)\n",
        "    # hist = plt.hist()\n",
        "    for d in des:\n",
        "      idx = kmeans_siftFeatures_trainX.predict([d])\n",
        "      histo[idx] += 1/nkp # Because we need normalized histograms, I prefere to add 1/nkp directly\n",
        "\n",
        "  histo_siftFeatures_valX.append(histo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [02:08<00:00,  9.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcX6zy2Dm6sV",
        "outputId": "2e037db7-58f2-42bb-ad08-1ca6bd60d564"
      },
      "source": [
        "print(np.vstack(histo_siftFeatures_trainX).shape)\n",
        "print(np.vstack(histo_siftFeatures_valX).shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4800, 20)\n",
            "(1200, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1NSEvJLiPTw"
      },
      "source": [
        "trainData = pd.DataFrame(histo_siftFeatures_trainX)\n",
        "trainData['labels']=0\n",
        "trainData['labels'][0:2400]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcpOC9jTxOsw",
        "outputId": "22d86e7f-ba69-4944-8949-0cee805f6ca7"
      },
      "source": [
        "valData = pd.DataFrame(histo_siftFeatures_valX)\n",
        "valData['labels']=0\n",
        "valData['labels'][0:600]=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFT3Z-ElyuKt"
      },
      "source": [
        "#trainData.to_csv('/drive/My Drive/CAD_1_1/rawSIFT_hairRemoved_Train.csv',index=False)\n",
        "#valData.to_csv('/drive/My Drive/CAD_1_1/rawSIFT_hairRemoved_val.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V350YwUv5QVK"
      },
      "source": [
        "trainDataShuffle=trainData.sample(frac=1)\n",
        "valDataShuffle=valData.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-DgFQ40WlWA"
      },
      "source": [
        "trainDataShuffle.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U8rBJCrzQ4U",
        "outputId": "d9d6706c-bfe3-4038-9834-829658040204"
      },
      "source": [
        "mlp = MLPClassifier(verbose=False, max_iter=600000)\n",
        "mlp.fit(trainDataShuffle.drop([\"labels\"],axis=1), trainDataShuffle['labels'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=600000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkk-3Agq1A09",
        "outputId": "46b11e6f-25da-4261-94b0-bbd46767894a"
      },
      "source": [
        "mlp.score(valDataShuffle.drop([\"labels\"],axis=1),valDataShuffle['labels'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7341666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZBOz8Tp2A6A",
        "outputId": "acfc23b8-054e-45a5-9cc4-8bc8cfd03403"
      },
      "source": [
        "rndst=RandomForestClassifier(n_estimators=100)\n",
        "rndst.fit(trainDataShuffle.drop([\"labels\"],axis=1), trainDataShuffle['labels'])\n",
        "rndst.score(valDataShuffle.drop([\"labels\"],axis=1),valDataShuffle['labels'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.73"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrOOKl2a6Vv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417b5273-76e3-4903-e2a0-345c82781e49"
      },
      "source": [
        "\n",
        "best_svc = SVC()\n",
        "best_svc.fit(trainDataShuffle.drop([\"labels\"],axis=1), trainDataShuffle['labels'])\n",
        "best_svc.score(valDataShuffle.drop([\"labels\"],axis=1),valDataShuffle['labels'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7316666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}